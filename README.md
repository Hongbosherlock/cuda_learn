## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ª **CUDA ç®—å­å­¦ä¹ åº“**ï¼Œæ—¨åœ¨é€šè¿‡å®ç°å¸¸è§çš„æ·±åº¦å­¦ä¹ ç®—å­æ¥å­¦ä¹  CUDA ç¼–ç¨‹å’Œ GPU ä¼˜åŒ–æŠ€æœ¯ã€‚é¡¹ç›®åŒ…å«å¤šç§æ ¸å¿ƒç®—å­çš„é«˜æ€§èƒ½ CUDA å®ç°ï¼Œå¹¶æä¾›äº†ä¸ PyTorch çš„æ— ç¼é›†æˆã€‚

## ç®—å­åˆ—è¡¨

### âœ… å·²å®ç°

- **Reduction ç®—å­**
  - `reduce_sum`: å¼ é‡æ±‚å’Œï¼Œæ”¯æŒå¤šç§è§„çº¦ç­–ç•¥

- **Quantization ç®—å­**
  - `per_token_quant_fp8`: Per-token FP8 é‡åŒ–ï¼ˆæ”¯æŒ float16/bfloat16 â†’ FP8 E4M3ï¼‰

### ğŸš§ è§„åˆ’ä¸­

- **Matrix Multiplication (GEMM)**
  - æ ‡å‡†çŸ©é˜µä¹˜æ³•
  - Tensor Core ä¼˜åŒ–ç‰ˆæœ¬
  - INT8/FP16 æ··åˆç²¾åº¦ GEMM

- **Normalization ç®—å­**
  - LayerNorm
  - RMSNorm
  - GroupNorm

- **Activation ç®—å­**
  - Softmax
  - GELU
  - SiLU/Swish

## é¡¹ç›®ç»“æ„

```
cuda_learn/
â”œâ”€â”€ kernel/               # CUDA kernel å®ç°
â”‚   â”œâ”€â”€ reduce/          # Reduction ç®—å­
â”‚   â”‚   â””â”€â”€ reduce_sum.cu
â”‚   â”œâ”€â”€ quant/           # é‡åŒ–ç®—å­
â”‚   â”‚   â””â”€â”€ per_token_quant_fp8.cu
â”‚   â”œâ”€â”€ matmul/          # çŸ©é˜µä¹˜æ³•ï¼ˆè§„åˆ’ä¸­ï¼‰
â”‚   â”œâ”€â”€ norm/            # å½’ä¸€åŒ–ç®—å­ï¼ˆè§„åˆ’ä¸­ï¼‰
â”‚   â””â”€â”€ activation/      # æ¿€æ´»å‡½æ•°ï¼ˆè§„åˆ’ä¸­ï¼‰
â”œâ”€â”€ test/                # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ test_reduce_sum.py
â”‚   â””â”€â”€ test_per_token_quant_fp8.py
â”œâ”€â”€ pyblind.cpp          # PyBind11 ç»‘å®šä»£ç 
â”œâ”€â”€ setup.py             # æ„å»ºé…ç½®
â””â”€â”€ README.md            # æœ¬æ–‡æ¡£
```

## ç‰¹æ€§

- âœ… **PyTorch åŸç”Ÿé›†æˆ**ï¼šç›´æ¥æ”¯æŒ `torch.Tensor`ï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç† GPU å†…å­˜
- âœ… **å¤šç²¾åº¦æ”¯æŒ**ï¼šæ”¯æŒ FP32ã€FP16ã€BF16ã€FP8 ç­‰å¤šç§æ•°æ®ç±»å‹
- âœ… **é«˜æ€§èƒ½ä¼˜åŒ–**ï¼š
  - å…±äº«å†…å­˜ä¼˜åŒ–
  - Warp-level primitives
  - å‘é‡åŒ–å†…å­˜è®¿é—®
  - Occupancy ä¼˜åŒ–
- âœ… **å®Œå–„çš„æµ‹è¯•**ï¼šæ¯ä¸ªç®—å­éƒ½é…å¤‡ç²¾åº¦æµ‹è¯•å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•
- âœ… **æ˜“äºæ‰©å±•**ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œæ–¹ä¾¿æ·»åŠ æ–°ç®—å­

## ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- NVIDIA GPU (Compute Capability >= 7.0)
- æ¨èï¼šAmpere (SM 80+) æˆ– Hopper (SM 90+) æ¶æ„

### è½¯ä»¶è¦æ±‚
- **CUDA Toolkit** >= 11.0
- **Python** >= 3.8
- **PyTorch** >= 2.0 (with CUDA support)
- **C++ ç¼–è¯‘å™¨** (gcc >= 7.0 or clang)

## å®‰è£…æ­¥éª¤

### 1. å…‹éš†ä»“åº“

```bash
git clone <repository_url>
cd cuda_learn
```

### 2. å®‰è£… Python ä¾èµ–

```bash
pip install torch numpy
```

### 3. ç¼–è¯‘å®‰è£…

#### æ ‡å‡†å®‰è£…
```bash
python setup.py install
```

#### å¼€å‘æ¨¡å¼ï¼ˆæ¨èç”¨äºå­¦ä¹ å’Œè°ƒè¯•ï¼‰
```bash
python setup.py develop
```

#### æ¸…ç†æ„å»ºæ–‡ä»¶
```bash
python setup.py clean --all
```

## ä½¿ç”¨ç¤ºä¾‹

### Reduce Sum

```python
import torch
import cuda_reduce

# åˆ›å»ºè¾“å…¥å¼ é‡
x = torch.randn(1024, 2048, dtype=torch.float32, device='cuda')

# è°ƒç”¨ CUDA kernel
result = cuda_reduce.reduce_sum(x)

print(f"Sum: {result.item()}")
```

### Per-Token FP8 Quantization

```python
import torch
import cuda_reduce

# è¾“å…¥: [num_tokens, hidden_dim]
x = torch.randn(512, 4096, dtype=torch.float16, device='cuda')

# é‡åŒ–åˆ° FP8
output, scale = cuda_reduce.per_token_quant_fp8(x)

print(f"Output dtype: {output.dtype}")  # torch.float8_e4m3fn
print(f"Scale shape: {scale.shape}")    # [512]
```

## è¿è¡Œæµ‹è¯•

### æµ‹è¯•å•ä¸ªç®—å­

```bash
# æµ‹è¯• reduce_sum
python test/test_reduce_sum.py

# æµ‹è¯• per_token_quant_fp8
python test/test_per_token_quant_fp8.py
```

### æ€§èƒ½åˆ†æ

```bash
# ä½¿ç”¨ NSight Compute è¿›è¡Œæ€§èƒ½åˆ†æ
ncu --set full -o profile_output python test/test_per_token_quant_fp8.py
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

å½“å‰å®ç°å¯è¿›ä¸€æ­¥ä¼˜åŒ–ï¼š

1. **Warp-levelä¼˜åŒ–**ï¼šä½¿ç”¨ `__shfl_down_sync` å‡å°‘å…±äº«å†…å­˜
2. **å‘é‡åŒ–åŠ è½½**ï¼šä½¿ç”¨ `float4` æå‡å¸¦å®½åˆ©ç”¨ç‡
3. **æµæ°´çº¿**ï¼šé‡å è®¡ç®—ä¸æ•°æ®ä¼ è¾“
4. **èåˆkernel**ï¼šå‡å°‘kernelå¯åŠ¨å¼€é”€

ç¤ºä¾‹ï¼šWarp shuffleä¼˜åŒ–
```cuda
template <typename T>
__device__ T warpReduceSum(T val) {
    for (int offset = 16; offset > 0; offset /= 2)
        val += __shfl_down_sync(0xffffffff, val, offset);
    return val;
}
```

## æ‰©å±•æ–¹å‘

- [ ] æ”¯æŒå¤šç§è§„çº¦æ“ä½œï¼ˆmax, min, prodï¼‰
- [ ] æ”¯æŒå¤šç»´tensorè§„çº¦
- [ ] å®ç°Warp shuffleä¼˜åŒ–
- [ ] æ·»åŠ FP8æ”¯æŒ
- [ ] æ”¯æŒç¨€ç–tensor

## å‚è€ƒèµ„æ–™

- [CUDA Programming Guide - Reduction](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#reduction)
- [PyTorch C++ Extension](https://pytorch.org/tutorials/advanced/cpp_extension.html)
- [Optimizing Parallel Reduction in CUDA (Mark Harris)](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf)

## License

MIT License